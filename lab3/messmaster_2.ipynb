{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# MessMaster: the Curse of the Muffin-Faced Dog (part 2)\n",
    "\n",
    "<div>\n",
    "<img src=\"media/domino_meme.png\" width=\"400\"/>\n",
    "</div>\n",
    "\n",
    "Welcome back to the quest of MessMaster! \n",
    "\n",
    "This week, we will continue to help Boltzmann differentiate Chihuahuas and blueberry muffins, but with fancier models (no longer just linear)!\n",
    "\n",
    "<div>\n",
    "<img src=\"../lab2/media/chihuahua_muffin.png\" width=\"400\"/>\n",
    "</div>\n",
    "\n",
    "Specifically we will use the following concepts:\n",
    "\n",
    "- Backprop: implementation and visualization\n",
    "- MLP: decision boundary and contrast with linear models\n",
    "- Optimization: Comparing SGD v.s. Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A friend has helped us found a separable 2D embedding of Chihuahuas and blueberry muffins.\n",
    "However, it is not linearly separable!\n",
    "\n",
    "<div>\n",
    "<img src=\"secret/data/xor_pattern_label.png\" width=\"400\"/>\n",
    "</div>\n",
    "\n",
    "\n",
    "We will train a MLP to help with this!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. ManualGrad: handcrafted gradients, artisanal machine learning\n",
    "\n",
    "Backprop is the process of computing the gradient of the loss function w.r.t. all the parameters from multiple stages of nonlinear transformations of the input. \n",
    "\n",
    "It is efficient both in terms of computation and memory and is universally used for computing the gradient and in well-implemented in many widely used tools (e.g., ```torch.autograd```). \n",
    "\n",
    "Today, we will implement backprop by hand  for a 2-layer MLP because it's a good exercise for understanding backprop :) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we will load the data and split it into train/val/test sets.\n",
    "\n",
    "**Q1a.** Why is it important to have validation and test sets?\n",
    "\n",
    "Answer: \n",
    "\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For reproducibility\n",
    "RANDOM_SEED = 10011  # postal code of CDS <3\n",
    "\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "# load data\n",
    "df = pd.read_csv(\"secret/data/xor_pattern.csv\")\n",
    "X = df[[\"x1\", \"x2\"]].values  # Extract features\n",
    "y = df[\"y\"].values  #\n",
    "\n",
    "# train-val-test split\n",
    "X_train, X_val_test, y_train, y_val_test = train_test_split(X, y, test_size=0.2, random_state=RANDOM_SEED)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_val_test, y_val_test, test_size=0.5, random_state=RANDOM_SEED)\n",
    "# TODO: what is the train-val-test split ratio?\n",
    "\n",
    "# convert to tensors\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.long)\n",
    "X_val_tensor = torch.tensor(X_val, dtype=torch.float32)\n",
    "y_val_tensor = torch.tensor(y_val, dtype=torch.long)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we define the loss function as the cross entropy loss. When we update the weights, we use the gradient of the loss function w.r.t. the weights."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q1b.** Implement the CEL loss function for binary classification. What is its connection to energy?\n",
    "\n",
    "Answer: \n",
    "\n",
    "<br>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(p_y_hat: torch.Tensor, y: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Compute the cross-entropy loss (negative log likelihood) of a prediction.\n",
    "    p_y_hat: probability of each class, shape (N, 2)\n",
    "    y: true class, shape (N,)\n",
    "    returns: loss, shape (1,)\n",
    "    \"\"\"\n",
    "    # TODO: implement the loss function\n",
    "    # step 1: fine the probability of the correct class\n",
    "    correct_class_loc = ??? # TODO: FILL IN\n",
    "    correct_class_prob = p_y_hat[correct_class_loc]\n",
    "    # step 2: compute the mean of the negative log likelihood across all examples\n",
    "    nll = ??? # TODO: FILL IN\n",
    "    return nll"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we dive into implementing the gradients, let's do a brief calculus review to make sure we have the background knowledge."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q1c.** \n",
    "\n",
    "i. What does derivative/gradient tells us about a function? (What does positive/negative gradient mean?)\n",
    "\n",
    "ii. Why is it useful for optimization?\n",
    "\n",
    "iii. What is chain rule and why is it relevant to backprop?\n",
    "\n",
    "Answer: \n",
    "\n",
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q1d.**\n",
    "\n",
    "We are going to implement a two-layer MLP with ReLU activation and softmax output.\n",
    "\n",
    "First layer: $z_1 = h_1(x) = \\sigma(W_1 x + b_1)=\\sigma(a_1)$\n",
    "\n",
    "Second layer: $z_2 = h_2(x) = W_2 z_1 + b_2$\n",
    "\n",
    "Softmax: $\\hat{p} = \\text{softmax}(z_2) = \\frac{e^{z_2}}{\\sum_{j=1}^{2} e^{z_{2j}}}$\n",
    "\n",
    "Loss function: $L(y, p_{\\hat{y}}) = \\text{L}_{\\text{ce}}(y, p_{\\hat{y}}) = - \\log \\hat{p}(\\hat{y}=y)$\n",
    "\n",
    "Consider computing the gradient of the loss function with respect to the parameters.\n",
    "\n",
    "Let's focus on the first layer. What is $\\frac{\\partial L}{\\partial W_1}$?\n",
    "\n",
    "You may use the fact that $\\frac{\\partial L}{\\partial z_2} = \\hat{p} - y$ and that $\\sigma'(a) = 1(\\sigma(a) > 0)$, where $1(\\cdot)$ is the indicator function.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div>\n",
    "<img src=\"media/grad_math.jpeg\" width=\"800\"/>\n",
    "</div>\n",
    "\n",
    "(Note: I should have used $\\partial$ (partial derivative) instead of $d$ in the figure since loss is a multivariable function, but it's too late to change it now.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer:\n",
    "\n",
    "<br><br><br><br>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q1e. Verification of gradients implementation**\n",
    "\n",
    "Check the gradients and gradient updates. Anything looks wrong?\n",
    "If you find something wrong, try to fix it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize weights\n",
    "d = 2\n",
    "h = 10\n",
    "k = 2\n",
    "W1 = torch.randn(d, h, requires_grad=False) * 0.01\n",
    "b1 = torch.zeros(h, requires_grad=False)\n",
    "W2 = torch.randn(h, k, requires_grad=False) * 0.01\n",
    "b2 = torch.zeros(k, requires_grad=False)\n",
    "\n",
    "learning_rate = 0.1\n",
    "epochs = 10000\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # =================== Forward pass ===================\n",
    "    # First layer: z1 = W1 * X + b1\n",
    "    z1 = X_train_tensor @ W1 + b1  # Shape: (N, h)  [batch_size, hidden_dim]\n",
    "\n",
    "    # Apply activation function: a1 = ReLU(z1)\n",
    "    a1 = torch.relu(z1)  # Shape: (N, h)\n",
    "\n",
    "    # Second layer: z2 = W2 * a1 + b2\n",
    "    z2 = a1 @ W2 + b2  # Shape: (N, k)  [batch_size, num_classes]\n",
    "\n",
    "    # Apply softmax to get probabilities: p_hat = softmax(z2)\n",
    "    p_hat = torch.softmax(z2, dim=1)   # Shape: (N, k)\n",
    "\n",
    "    # =================== Compute Loss ===================\n",
    "    # PyTorch's CrossEntropyLoss automatically applies softmax inside,\n",
    "    # so we should pass raw logits (z2), not softmax probabilities (p_hat)\n",
    "    loss = loss_fn(p_hat, y_train_tensor)  # Scalar loss value\n",
    "\n",
    "    # =================== Backpropagation ===================\n",
    "\n",
    "    # Step 1: Compute gradient of loss w.r.t. logits (z2)\n",
    "    # Cross-entropy loss with softmax:\n",
    "    #   L = - (1/N) * sum(y * log(p_hat))\n",
    "    # Derivative:\n",
    "    #   dL/dz2 = (p_hat - y) / N\n",
    "    # Shape: (N, k) [Same as z2]\n",
    "    y_one_hot = torch.nn.functional.one_hot(y_train_tensor, num_classes=p_hat.shape[1]).float()  # Shape: (N, k)\n",
    "    dL_dz2 = (p_hat - y_one_hot) / y_train_tensor.shape[0]  # Normalize by batch size\n",
    "\n",
    "    # Step 2: Compute gradient of loss w.r.t. W2 and b2\n",
    "    # Using chain rule: dL/dW2 = (dL/dz2) * (dz2/dW2)\n",
    "    #   dz2/dW2 = a1^T\n",
    "    #   dL/dW2 = a1^T @ dL/dz2\n",
    "    # Shape: (h, k) [Same as W2]\n",
    "    dL_dW2 = a1.T @ dL_dz2\n",
    "\n",
    "    # Gradient of loss w.r.t. b2:\n",
    "    #   dL/db2 = sum(dL/dz2) along batch axis\n",
    "    # Shape: (k,) [Same as b2]\n",
    "    dL_db2 = torch.sum(dL_dz2, dim=0)\n",
    "\n",
    "    # Step 3: Compute gradient of loss w.r.t. activations (a1)\n",
    "    #   dL/da1 = (dL/dz2) * (dz2/da1)\n",
    "    #   dz2/da1 = W2^T\n",
    "    #   dL/da1 = dL/dz2 @ W2^T\n",
    "    # Shape: (N, h) [Same as a1]\n",
    "    dL_da1 = dL_dz2 @ W2.T \n",
    "\n",
    "    # Step 4: Compute gradient of loss w.r.t. pre-activation (z1)\n",
    "    # Using chain rule: dL/dz1 = (dL/da1) * (da1/dz1)\n",
    "    # ReLU derivative:\n",
    "    #   da1/dz1 = 1 if z1 > 0, else 0\n",
    "    # Shape: (N, h) [Same as z1]\n",
    "    dL_dz1 = dL_da1 * (z1 > 0).float() \n",
    "\n",
    "    # Step 5: Compute gradient of loss w.r.t. W1 and b1\n",
    "    # Using chain rule: dL/dW1 = (dL/dz1) * (dz1/dW1)\n",
    "    #   dz1/dW1 = X^T\n",
    "    #   dL/dW1 = X^T @ dL/dz1\n",
    "    # Shape: (d, h) [Same as W1]\n",
    "    # TODO: check if this is correct\n",
    "    dL_dW1 = X_train_tensor.T @ dL_dz1 \n",
    "\n",
    "    # Gradient of loss w.r.t. b1:\n",
    "    #   dL/db1 = sum(dL/dz1) along batch axis\n",
    "    # Shape: (h,) [Same as b1]\n",
    "    dL_db1 = torch.sum(dL_dz1, dim=0)\n",
    "\n",
    "    # Gradient update (SGD step)\n",
    "    # TODO: check here\n",
    "    W1 += learning_rate * dL_dW1\n",
    "    b1 += learning_rate * dL_db1\n",
    "    W2 += learning_rate * dL_dW2\n",
    "    b2 += learning_rate * dL_db2\n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "        print(f\"Epoch {epoch}: Loss = {loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Visualization**\n",
    "\n",
    "Now let's visualize the decision boundary of the trained MLP.\n",
    "\n",
    "Can linear models learn this decision boundary?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from util import plot_decision_boundary\n",
    "# Example usage:\n",
    "plot_decision_boundary(W1, b1, W2, b2, X_train_tensor.numpy(), y_train_tensor.numpy(), split=\"Train\")\n",
    "plot_decision_boundary(W1, b1, W2, b2, X_val_tensor.numpy(), y_val_tensor.numpy(), split=\"Val\")\n",
    "plot_decision_boundary(W1, b1, W2, b2, X_test_tensor.numpy(), y_test_tensor.numpy(), split=\"Test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Optimizers: Adam v.s. SGD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great that the MLP worked! However, we can further accelerate the training process by dynamically adjusting the learning rate.\n",
    "\n",
    "**Q2a.** What was the learning rate scheduler we used above?\n",
    "\n",
    "Answer: \n",
    "\n",
    "<br><br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In class, we learned about the Adam optimizer, which uses exponential smoothing to reduce the variance of the gradient estimate and normalizes the update using an estimate of the second moment of the gradient.\n",
    "\n",
    "$$ \\theta_t^i \\leftarrow \\theta_{t-1}^i + \\alpha \\frac{m_t^i}{\\sqrt{v_t^i + \\epsilon}},$$\n",
    "\n",
    "where $\\alpha$ is the default learning rate, $m_t$ is the momentum (exponential moving average of the gradient), and $v_t$ is the adpative scaling (exponential moving average of the squared gradient).\n",
    "$$m_t \\leftarrow \\beta_1 m_{t-1} + (1-\\beta_1) g_t.$$\n",
    "$$v_t \\leftarrow \\beta_2 v_{t-1} + (1-\\beta_2) g_t^2.$$\n",
    "\n",
    "**Q2b.** Why is it momentum helpful? Why is adaptive scaling helpful?\n",
    "\n",
    "Answer: \n",
    "\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q2c.** Observe the loss curves of SGD and Adam. What do you see?\n",
    "\n",
    "Answer: \n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "W1.requires_grad = True\n",
    "W2.requires_grad = True\n",
    "b1.requires_grad = True\n",
    "b2.requires_grad = True\n",
    "# Hyperparameters\n",
    "epochs = 10000\n",
    "batch_size = 32\n",
    "learning_rate = 0.1 #1e-3\n",
    "\n",
    "# Initialize weights with Xavier (Glorot) initialization\n",
    "torch.manual_seed(RANDOM_SEED)  # For reproducibility\n",
    "torch.nn.init.xavier_uniform_(W1)\n",
    "torch.nn.init.xavier_uniform_(W2)\n",
    "b1.data.fill_(0)\n",
    "b2.data.fill_(0)\n",
    "\n",
    "# Define two optimizers: SGD and Adam\n",
    "optimizer_sgd = torch.optim.SGD([W1, b1, W2, b2], lr=learning_rate)\n",
    "optimizer_adam = torch.optim.Adam([W1, b1, W2, b2], lr=learning_rate)\n",
    "\n",
    "# Store loss & lr history\n",
    "loss_history_sgd, loss_history_adam = [], []\n",
    "lr_history_sgd, lr_history_adam = [], []\n",
    "\n",
    "# Training loop for both optimizers\n",
    "for optimizer_name, optimizer, loss_history, lr_history in [\n",
    "    (\"SGD\", optimizer_sgd, loss_history_sgd, lr_history_sgd),\n",
    "    (\"Adam\", optimizer_adam, loss_history_adam, lr_history_adam),\n",
    "]:\n",
    "    print(f\"\\nTraining with {optimizer_name}...\\n\")\n",
    "\n",
    "    # Reset weights for fair comparison\n",
    "    torch.nn.init.xavier_uniform_(W1)\n",
    "    torch.nn.init.xavier_uniform_(W2)\n",
    "    b1.data.fill_(0)\n",
    "    b2.data.fill_(0)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        # =================== Forward pass ===================\n",
    "        z1 = X_train_tensor @ W1 + b1\n",
    "        a1 = torch.relu(z1)\n",
    "        z2 = a1 @ W2 + b2\n",
    "        loss = F.cross_entropy(z2, y_train_tensor)\n",
    "\n",
    "        # =================== Backward pass ===================\n",
    "        optimizer.zero_grad()  # Reset gradients\n",
    "        loss.backward()  # Compute gradients\n",
    "        optimizer.step()  # Update weights\n",
    "\n",
    "        # Save loss & learning rate\n",
    "        loss_history.append(loss.item())\n",
    "\n",
    "        lr_history.append(optimizer.param_groups[0][\"lr\"])  # Extract current lr\n",
    "\n",
    "        # Print progress every 10 epochs\n",
    "        if epoch % 10 == 0:\n",
    "            print(\n",
    "                f\"{optimizer_name} - Epoch {epoch}: Loss = {loss.item():.4f}, LR = {optimizer.param_groups[0]['lr']:.6f}\"\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from .util import plot_loss\n",
    "plot_loss(loss_history_sgd, loss_history_adam)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
